{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c78f6532",
   "metadata": {},
   "source": [
    "### 第5章 AIエージェント×ワークフローによる作業自動化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ff36b3",
   "metadata": {},
   "source": [
    "ライブラリのimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d099804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import yaml\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e5e8b5",
   "metadata": {},
   "source": [
    "【注意】下記実行前にREADME.mdに従いルートフォルダにconfig.yamlを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29266156",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as yml:\n",
    "    config = yaml.safe_load(yml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cef04a7",
   "metadata": {},
   "source": [
    "クライアントの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ba7c986",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key = config[\"oai\"][\"key\"], # 取得したAPIキー\n",
    "    # base_url= <URL> # Azure OpenAI Serviceを使う場合は必要\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322f3280",
   "metadata": {},
   "source": [
    "5.1 指示プロンプト例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbcc210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"\n",
    "\n",
    "# Role\n",
    "あなたはコンサルティングファームの週次ニュース調査・事例突合・レポート配信を行うツール駆動エージェントです。\n",
    "<operating_mode>\n",
    "- すべての作業はツール呼び出しで完結する。\n",
    "- 最終出力は必ず send_email の tool call で終了する。\n",
    "</operating_mode>\n",
    "\n",
    "# Task\n",
    "<workflow>\n",
    "Phase1: 入力理解・期間確定\n",
    "Phase2: web_search でニュース収集(複数クエリ)\n",
    "Phase3: 重要度選別・要約・タグ付け\n",
    "Phase4: case_search で社内事例突合\n",
    "Phase5: report_request_approval でレポート生成・承認依頼\n",
    "Phase6: report_request_approval → approved 確認(承認されなければ指摘を反映し再依頼)\n",
    "Phase7: send_email で配信(最終)\n",
    "</workflow>\n",
    "\n",
    "# Input\n",
    "<input_schema>\n",
    "(【略】InputのJSONスキーマとそれぞれのプロパティ説明)\n",
    "</input_schema>\n",
    "\n",
    "# Tool\n",
    "Taskのworkflow内におけるPhaseを思考中に必ず確認し、適切なツールを呼び出して作業を進める。\n",
    "\n",
    "<tool_usage_rules>\n",
    "- 根拠になった情報は検索結果および格納先のURLを[<リンク>]として必ず付与する。\n",
    "</tool_usage_rules>\n",
    "\n",
    "\n",
    "## report_request_approval\n",
    "出力にはreport_template_markdownテンプレートを用いる\n",
    "<report_template_markdown>\n",
    "## サマリ(3〜6行)\n",
    "- (最重要トピックを最大3点)\n",
    "\n",
    "## 今週の重要動向(最大5件)\n",
    "- [重要度: 高/中/低] 見出し\n",
    "\n",
    "## 過去事例との突合(最大5件)\n",
    "- 事例ID/パス: ...\n",
    "\n",
    "## リスク/機会と推奨アクション(最大5件)\n",
    "- (アクションは「誰が/何を/いつまでに」が分かる書き方)\n",
    "\n",
    "## 前提・不確実性(必須)\n",
    "- (推測は推測と明記。未確認は未確認と明記)\n",
    "</report_template_markdown>\n",
    "\n",
    "# Policy\n",
    "<quality_and_grounding>\n",
    "- 根拠のない断定は禁止。日付・数字・固有名詞は特に厳密。\n",
    "- 矛盾があれば追加検索し、解消できなければ不一致として記載。\n",
    "</quality_and_grounding>\n",
    "\n",
    "<privacy_and_handling>\n",
    "- 社内事例DBの詳細を社外共有しない前提で、メール本文は要約＋参照ID/パスに留める。\n",
    "</privacy_and_handling>\n",
    "\"\"\"\n",
    "\n",
    "report_request_approval_description = \"\"\"\n",
    "Purpose: 収集済みニュースと社内事例をもとにレポートMarkdownを生成し、承認依頼として保存・申請します。\n",
    "\n",
    "Use when:\n",
    "- Phase5、および承認が下りなかった場合の再承認依頼時\n",
    "- 対象顧客・期間・想定読者などの前提と必要情報（ニュース要約・事例・推奨アクション）が揃っている\n",
    "\n",
    "Do not use when:\n",
    "- Phase5以外\n",
    "- 収集・分析が未完了で、まず要件や前提条件の確認が必要な状態\n",
    "\n",
    "Notes:\n",
    "- 失敗時: 生成したレポートは保持したまま簡潔に指摘内容を反映し、再試行。\n",
    "\"\"\"\n",
    "\n",
    "report_markdown_description = \"\"\"\n",
    "以下の点を遵守してレポートを作成してください。\n",
    "- レポートはreport_template_markdownテンプレートに従い、冗長な叙述を避ける(箇条書き中心)。\n",
    "- 入力スコープ(顧客・業界・地域・論点・期間)を逸脱しない。\n",
    "- 不足情報は「仮定」として明示。\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2962d814",
   "metadata": {},
   "source": [
    "5.2 report_request_approvalツール定義例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3d224e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\"type\": \"web_search\"},\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"report_request_approval\",\n",
    "        \"description\": report_request_approval_description,\n",
    "        \"strict\": True,\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "            \"report_markdown\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": report_markdown_description\n",
    "            }\n",
    "            },\n",
    "            \"required\": [\"report_markdown\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ded2f84",
   "metadata": {},
   "source": [
    "5.5 リクエスト例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f068519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response_type:  function_call\n",
      "function_name:  report_request_approval\n",
      "argument:  {'report_markdown': '## サマリ(3〜6行)\\n- 全国的な地方路線の利用者回復の停滞と、自治体・事業者による近代化補助金の増額が同時進行している（架空）。[参照: 政府補助案概要の抜粋][https://news.example.com/rail-future-jan2026]\\n- 予知保全・デジタル双方向プラットフォームへの投資が加速。大手私鉄・第三セクターでパイロット導入が進行中（架空）。[参照: 事例概要][https://internal.example.com/case_summary/pdm2026]\\n- 貨物需要の回復に伴い、複合輸送での鉄道比率拡大の機会が出現。短期は設備・運用調整が必要（架空）。[参照: 物流業界調査][https://news.example.com/logistics-rail-jan2026]\\n\\n## 今週の重要動向(最大5件)\\n- [重要度: 高] 政府の『地域鉄道近代化補助プログラム』増額案（公募開始想定：2026-02-15）。公的資金で老朽設備更新とデジタル化を同時支援。[資料: 補助案概要][https://news.example.com/rail-future-jan2026]\\n- [重要度: 高] 大手私鉄A社が予知保全プラットフォームを本格運用へ（パイロット完了、段階的展開2026 Q2開始想定）。保守コスト削減と稼働率改善を見込む。[社内メモ][https://internal.example.com/case_summary/pdm2026]\\n- [重要度: 中] 都市部通勤需要はコロナ前比で85〜92%のレンジで停滞。テレワーク定着が継続的影響を与える見通し（短期需要リスク）。[市場データ][https://news.example.com/ridership-data-jan2026]\\n- [重要度: 中] 物流業界で鉄道回帰の動き。長距離トラックコスト上昇により、鉄道貨物の競争力が改善（機会）。[業界レポート][https://news.example.com/logistics-rail-jan2026]\\n- [重要度: 低] 水素動力車両の実証実験で複数社が参画。商用化は中長期の見込みだが自治体の後押しあり（注目トピック）。[実証概要][https://news.example.com/hydrogen-train-jan2026]\\n\\n## 過去事例との突合(最大5件)\\n- 事例ID/パス: CASE-R-2021-07 / 社内: /cases/regional_restructuring/CASE-R-2021-07（地方路線の再編・自治体連携による存続モデル）\\n- 事例ID/パス: CASE-M-2023-11 / 社内: /cases/predictive_maintenance/CASE-M-2023-11（予知保全プラットフォーム導入による故障削減）\\n- 事例ID/パス: CASE-F-2024-02 / 社内: /cases/freight_optimization/CASE-F-2024-02（複合輸送での鉄道比率向上プロジェクト）\\n\\n## リスク/機会と推奨アクション(最大5件)\\n- リスク: 老朽インフラの集中故障・規制対応コスト増。推奨アクション: インフラ奉行チームは『上位10橋梁・トンネルの緊急点検リスト』を作成し、2026-03-31までに臨時予算要求案を経営に提出すること。 (誰が: インフラ奉行チーム、何を: 緊急点検リスト作成＋予算案、いつまでに: 2026-03-31)\\n- 機会: 予知保全を外販し新規収益化。推奨アクション: 事業開発部は2026-05-31までに中～小規模事業者向けのパイロット提案書を作成し、2社と2026 Q3に試行契約を結ぶ。 (誰が: 事業開発部、何を: パイロット提案書作成・契約、いつまでに: 2026-05-31)\\n- リスク/機会: 都市通勤需要の構造変化。推奨アクション: 営業企画部は2026-04-15までに『通勤需要弾力性調査』を実施し、料金・ダイヤ改革案を含めた試算を提示する。 (誰が: 営業企画部、何を: 需要調査＋改革案、いつまでに: 2026-04-15)\\n\\n## 前提・不確実性(必須)\\n- 本レポートは架空シナリオに基づく想定報告。政府補助や企業動向の日付・内容は仮定であり、実際の公表資料がある場合はそれを優先すること（未確認）。\\n- 社内事例の参照はID/パスのみを記載。詳細データは社内DB参照のこと（外部共有不可）。\\n- 市場需要の予測は現行トレンド（テレワーク継続・物流コスト上昇）をベースにしており、突発的な経済・政策変化で数値は大きく変動しうる（推測）。\\n\\n# 備考\\n- 本報告内の外部参照リンクは例示的なプレースホルダです。実運用時は実ソースURLを付与してください。'}\n",
      "id:  call_5xiqCQaUIIIxxTxzhDPxf0Hh\n"
     ]
    }
   ],
   "source": [
    "messages=[\n",
    "        {\"role\": \"developer\", \"content\": instruction},\n",
    "        {\"role\": \"user\", \"content\": \"鉄道業界の架空のレポートが出せる状態になった想定で、Phase5に入ったとして、ツール選択してください。レポートは架空のものを作ってください。\"}\n",
    "    ]\n",
    "\n",
    "response = client.responses.create(\n",
    "    instructions=instruction,\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"required\"\n",
    ")\n",
    "\n",
    "response_type = response.output[1].type\n",
    "function_name = response.output[1].name\n",
    "arguments = json.loads(response.output[1].arguments)\n",
    "id = response.output[1].call_id\n",
    "\n",
    "print(\"response_type: \", response_type)\n",
    "print(\"function_name: \", function_name)\n",
    "print(\"argument: \", arguments)\n",
    "print(\"id: \", id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd24aa59",
   "metadata": {},
   "source": [
    "5.7 Conversations APIの履歴管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "927e4042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 会話履歴の格納先を生成\n",
    "conversation = client.conversations.create()\n",
    "\n",
    "# ツール使用結果とReasoning過程を会話履歴に含める設定でLLMにテキスト生成リクエスト\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-5-nano\",\n",
    "  input=[\n",
    "    {\"role\": \"system\", \"content\": \"要求された内容だけ答えてください。\"},\n",
    "    {\"role\": \"user\", \"content\": \"LLMのRAGに関連するキーワードとその簡易解説を1つ出力して。\"}\n",
    "  ],\n",
    "  tools = [\n",
    "    {\"type\": \"web_search\"}\n",
    "  ],\n",
    "  reasoning = {\"summary\":\"detailed\"},\n",
    "  tool_choice=\"required\",\n",
    "  include=[\"web_search_call.action.sources\",  \"reasoning.encrypted_content\"],\n",
    "  conversation=conversation.id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106e08a1",
   "metadata": {},
   "source": [
    "5.8 ConversationsAPIの履歴出力例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91e3cb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type\": \"reasoning\",\n",
      "  \"summary\": [\n",
      "    \"**Considering web.run call**\\n\\nI need to make sure to call one of the defined tools immediately in response to the user's request, so I’m planning to perform a web.run call. I’ll provide a keyword like \\\"RAG: Retrieval-Augmented Generation\\\" and a simple explanation. I need to verify this through a search query to ensure accuracy. Since I'll be using web.run, I’ll also need to include citations for the information I gather. It’s essential to keep this straightforward while being accurate!\",\n",
      "    \"**Planning citations for RAG**\\n\\nThe instructions say that if I call web.run, all statements based on internet sources should have citations. I’m thinking of using \\\"Keyword: Retrieval-Augmented Generation (RAG)\\\" with an explanation that LLMs fetch relevant documents and generate answers. It's essential to reference authoritative sources, like the Facebook AI paper or possibly Wikipedia. I’ll need to perform web.run with four queries about RAG to gather enough information. Then I can read through the sources and prepare accurate citations!\",\n",
      "    \"**Simulating web.run call**\\n\\nI'm planning to call web.run with a set of queries about Retrieval-Augmented Generation (RAG). I’ll search for the RAG paper from arXiv, definitions, and explanations from sources like Hugging Face. My response will be short, focusing on providing just one keyword: \\\"Retrieval-Augmented Generation (RAG).\\\" The explanation will detail how it uses a retriever to fetch documents and a generator to create answers, highlighting its benefits for accuracy and knowledge. Citations will follow the explanation!\",\n",
      "    \"**Citing sources for RAG**\\n\\nI'm planning to cite some important sources for Retrieval-Augmented Generation. First, the arXiv paper titled \\\"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\\\" by Lewis et al. from 2020. I’ll also include a Hugging Face blog on RAG. While I could consider Wikipedia, I prefer using more credible sources like the arXiv paper and Hugging Face documentation. I’ll paraphrase information as needed to stay within word limits. It’s all about gathering the best references for accuracy!\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"type\": \"web_search_call\",\n",
      "  \"query\": \"Retrieval-Augmented Generation RAG paper arXiv Lewis 2020\"\n",
      "}\n",
      "{\n",
      "  \"type\": \"reasoning\",\n",
      "  \"summary\": []\n",
      "}\n",
      "{\n",
      "  \"type\": \"web_search_call\",\n",
      "  \"query\": \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks arXiv\"\n",
      "}\n",
      "{\n",
      "  \"type\": \"reasoning\",\n",
      "  \"summary\": []\n",
      "}\n",
      "{\n",
      "  \"type\": \"message\",\n",
      "  \"role\": \"assistant\",\n",
      "  \"text\": [\n",
      "    \"キーワード: Retrieval-Augmented Generation（RAG）\\n\\n簡易解説: LLMが外部データを検索して取り込み、その retrieved ドキュメントを前提に回答を生成する手法。知識集約タスクの正確性を高め、最新情報の反映や出典の提示を容易にする。出典として原著論文（2020年）と解説ページがある。 ([arxiv.org](https://arxiv.org/abs/2005.11401?utm_source=openai))\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for resp in response.output:\n",
    "    # print(resp)\n",
    "    if resp.type == 'reasoning':\n",
    "        print(json.dumps({\"type\": resp.type, \"summary\": [s.text for s in resp.summary]}, ensure_ascii=False, indent=2))\n",
    "    elif resp.type == 'web_search_call':\n",
    "        print(json.dumps({\"type\": resp.type, \"query\": resp.action.query}, ensure_ascii=False, indent=2))\n",
    "    elif resp.type == 'message':\n",
    "        print(json.dumps({\"type\": resp.type, \"role\": resp.role, \"text\": [c.text for c in resp.content if hasattr(c, 'text')]}, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2476042e",
   "metadata": {},
   "source": [
    "5.9 ConversationsAPIの履歴管理でReasoning過程を除外して再利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6e3d645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type\": \"message\",\n",
      "  \"role\": \"assistant\",\n",
      "  \"text\": [\n",
      "    \"キーワード: Retrieval-Augmented Generation（RAG）\\n\\n簡易解説: LLMが外部データを検索して取り込み、その retrieved ドキュメントを前提に回答を生成する手法。知識集約タスクの正確性を高め、最新情報の反映や出典の提示を容易にする。出典として原著論文（2020年）と解説ページがある。 ([arxiv.org](https://arxiv.org/abs/2005.11401?utm_source=openai))\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"type\": \"reasoning\",\n",
      "  \"summary\": []\n",
      "}\n",
      "{\n",
      "  \"type\": \"web_search_call\",\n",
      "  \"urls\": [],\n",
      "  \"query\": \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks arXiv\"\n",
      "}\n",
      "{\n",
      "  \"type\": \"reasoning\",\n",
      "  \"summary\": []\n",
      "}\n",
      "{\n",
      "  \"type\": \"web_search_call\",\n",
      "  \"urls\": [],\n",
      "  \"query\": \"Retrieval-Augmented Generation RAG paper arXiv Lewis 2020\"\n",
      "}\n",
      "{\n",
      "  \"type\": \"reasoning\",\n",
      "  \"summary\": [\n",
      "    \"**Considering web.run call**\\n\\nI need to make sure to call one of the defined tools immediately in response to the user's request, so I’m planning to perform a web.run call. I’ll provide a keyword like \\\"RAG: Retrieval-Augmented Generation\\\" and a simple explanation. I need to verify this through a search query to ensure accuracy. Since I'll be using web.run, I’ll also need to include citations for the information I gather. It’s essential to keep this straightforward while being accurate!\",\n",
      "    \"**Planning citations for RAG**\\n\\nThe instructions say that if I call web.run, all statements based on internet sources should have citations. I’m thinking of using \\\"Keyword: Retrieval-Augmented Generation (RAG)\\\" with an explanation that LLMs fetch relevant documents and generate answers. It's essential to reference authoritative sources, like the Facebook AI paper or possibly Wikipedia. I’ll need to perform web.run with four queries about RAG to gather enough information. Then I can read through the sources and prepare accurate citations!\",\n",
      "    \"**Simulating web.run call**\\n\\nI'm planning to call web.run with a set of queries about Retrieval-Augmented Generation (RAG). I’ll search for the RAG paper from arXiv, definitions, and explanations from sources like Hugging Face. My response will be short, focusing on providing just one keyword: \\\"Retrieval-Augmented Generation (RAG).\\\" The explanation will detail how it uses a retriever to fetch documents and a generator to create answers, highlighting its benefits for accuracy and knowledge. Citations will follow the explanation!\",\n",
      "    \"**Citing sources for RAG**\\n\\nI'm planning to cite some important sources for Retrieval-Augmented Generation. First, the arXiv paper titled \\\"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\\\" by Lewis et al. from 2020. I’ll also include a Hugging Face blog on RAG. While I could consider Wikipedia, I prefer using more credible sources like the arXiv paper and Hugging Face documentation. I’ll paraphrase information as needed to stay within word limits. It’s all about gathering the best references for accuracy!\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"type\": \"message\",\n",
      "  \"role\": \"user\",\n",
      "  \"text\": [\n",
      "    \"LLMのRAGに関連するキーワードとその簡易解説を1つ出力して。\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"type\": \"message\",\n",
      "  \"role\": \"system\",\n",
      "  \"text\": [\n",
      "    \"要求された内容だけ答えてください。\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "items = client.conversations.items.list(conversation.id, limit=10)\n",
    "\n",
    "for item in items.data:\n",
    "    # print(item)\n",
    "    if item.type == 'reasoning':\n",
    "        print(json.dumps({\"type\": item.type, \"summary\": [s.text for s in item.summary] if hasattr(item, 'summary') else []}, ensure_ascii=False, indent=2))\n",
    "    elif item.type == 'web_search_call':\n",
    "        sources = getattr(item.action, \"sources\", None) if hasattr(item, 'action') else None\n",
    "        print(json.dumps({\n",
    "            \"type\": item.type,\n",
    "            \"urls\": [src.url for src in sources] if sources else [],\n",
    "            \"query\": getattr(item.action, \"query\", None) if hasattr(item, 'action') else None\n",
    "        }, ensure_ascii=False, indent=2))\n",
    "    elif item.type == 'message':\n",
    "        print(json.dumps({\"type\": item.type, \"role\": item.role, \"text\": [c.text for c in item.content if hasattr(c, 'text')]}, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee0212",
   "metadata": {},
   "source": [
    "5.9 ConversationsAPIの履歴管理でReasoning過程を除外して再利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5ac2c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type\": \"message\",\n",
      "  \"text\": [\n",
      "    \"キーワード: Retrieval-Augmented Generation（RAG）\\n\\n簡易解説: LLMが外部データを検索して取り込み、その retrieved ドキュメントを前提に回答を生成する手法。知識集約タスクの正確性を高め、最新情報の反映や出典の提示を容易にする。出典として原著論文（2020年）と解説ページがある。 ([arxiv.org](https://arxiv.org/abs/2005.11401?utm_source=openai))\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"type\": \"web_search_call\",\n",
      "  \"urls\": [],\n",
      "  \"query\": \"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks arXiv\"\n",
      "}\n",
      "{\n",
      "  \"type\": \"web_search_call\",\n",
      "  \"urls\": [],\n",
      "  \"query\": \"Retrieval-Augmented Generation RAG paper arXiv Lewis 2020\"\n",
      "}\n",
      "{\n",
      "  \"type\": \"message\",\n",
      "  \"text\": [\n",
      "    \"LLMのRAGに関連するキーワードとその簡易解説を1つ出力して。\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"type\": \"message\",\n",
      "  \"text\": [\n",
      "    \"要求された内容だけ答えてください。\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "reasoning_msg_ids = [itm.id for itm in items.data if itm.type == \"reasoning\"]\n",
    "\n",
    "for msg_id in reasoning_msg_ids:\n",
    "   new_conversation = client.conversations.items.delete(conversation_id=conversation.id, item_id=msg_id)\n",
    "\n",
    "items = client.conversations.items.list(new_conversation.id, limit=10)\n",
    " \n",
    "for item in items.data:\n",
    "    # print(item)\n",
    "    if item.type == 'reasoning':\n",
    "        print(json.dumps({\"type\": item.type, \"summary\": [s.text for s in item.summary] if hasattr(item, 'summary') else []}, ensure_ascii=False, indent=2))\n",
    "    elif item.type == 'web_search_call':\n",
    "        sources = getattr(item.action, \"sources\", None) if hasattr(item, 'action') else None\n",
    "        print(json.dumps({\n",
    "            \"type\": item.type,\n",
    "            \"urls\": [src.url for src in sources] if sources else [],\n",
    "            \"query\": getattr(item.action, \"query\", None) if hasattr(item, 'action') else None\n",
    "        }, ensure_ascii=False, indent=2))\n",
    "    elif item.type == 'message':\n",
    "        print(json.dumps({\"type\": item.type, \"text\": [c.text for c in item.content if hasattr(c, 'text')]}, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdbfa20",
   "metadata": {},
   "source": [
    "5.10 Compact機能の使用例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c642dae",
   "metadata": {},
   "source": [
    "###### ※この例ではサンプルが小さいため、圧縮しても効果が薄いor元よりもトークンが大きくなる点に注意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74521d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "結果: 最新はGemini 3、Googleの最新モデル（2025年11月公開）。([blog.google](https://blog.google/products-and-platforms/products/gemini/gemini-3/?utm_source=openai))\n"
     ]
    }
   ],
   "source": [
    "# ダミーの会話を用意\n",
    "messages = [\n",
    "    {\"role\":\"system\",\"content\":\"あなたはLLMの専門家です。具体情報を交えて短め(最大50字程度)で答えてください。\"},\n",
    "    {\"role\":\"user\",\"content\":\"私は中学生です。GPT-5.2とGPT-4.1の位置づけを、用途別に教えてください。\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"GPT-5.2は推論対応の旗艦で、複雑なコーディングやエージェントに強いです。\"},\n",
    "    {\"role\":\"user\",\"content\":\"低コスト重視で遅延も抑えたいとき、GPT-5系はどう選びますか。\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"GPT-5 miniは速く安価で定型タスク向きで、さらに軽量ならGPT-5 nanoが候補です。\"},\n",
    "    {\"role\":\"user\",\"content\":\"長文を大量に扱う場合、推論なしで高文脈の選択肢はありますか。\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"推論ステップ不要ならGPT-4.1が約1M文脈で有力で、難問はGPT-5系も併用します。\"},\n",
    "    {\"role\":\"user\",\"content\":\"最新のモデルはGoogleだと何だろう？調べてくれる？\"}\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    tools=[{\"type\": \"web_search\"}],\n",
    "    include=[\"reasoning.encrypted_content\", \"web_search_call.action.sources\"],\n",
    "    input=messages,\n",
    "    store=True\n",
    ")\n",
    "\n",
    "print(\"結果:\", response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6060cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "非圧縮の結果: 推論対応の旗艦、複雑なコーディングとエージェントが得意。\n",
      "非圧縮のインプットトークン: 4901\n"
     ]
    }
   ],
   "source": [
    "# まずは非圧縮版で実行\n",
    "normal_response = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    tools=[{\"type\": \"web_search\"}],\n",
    "    include=[\"reasoning.encrypted_content\", \"web_search_call.action.sources\"],\n",
    "    previous_response_id=response.id,\n",
    "    input=[{\"role\": \"user\", \"content\": \"さっきGPT-5.2って何に強いって言ってました？\"}],\n",
    ")\n",
    "print(\"非圧縮の結果:\", normal_response.output_text)\n",
    "print(\"非圧縮のインプットトークン:\", normal_response.usage.input_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a77d6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hirosatogamo\\.virtualenvs\\pipenv-slS7I_su\\Lib\\site-packages\\pydantic\\main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `literal['output_text']` - serialized value may not be as expected [field_name='type', input_value='input_text', input_type=str])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ResponseOutputRefusal` - serialized value may not be as expected [field_name='content', input_value=ResponseOutputText(annota...ut_text', logprobs=None), input_type=ResponseOutputText])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圧縮後の結果: 最新情報（2025年12月公開）による GPT-5.2 の強みは以下です。\n",
      "- 長文・長文脈の理解と長期タスクの推進。 ([openai.com](https://openai.com/index/introducing-gpt-5-2//?utm_source=openai))\n",
      "- 表計算・プレゼン作成・コード作成など、実務的作業を高効率でこなす。 ([openai.com](https://openai.com/index/introducing-gpt-5-2//?utm_source=openai))\n",
      "- 画像認識・視覚的タスク対応。 ([openai.com](https://openai.com/index/introducing-gpt-5-2//?utm_source=openai))\n",
      "- ツール呼び出しを含むエージェント的動作・多段階自動化。 ([openai.com](https://openai.com/index/introducing-gpt-5-2//?utm_source=openai))\n",
      "- GDPval などのベンチマークで専門家レベルに近い/上回る性能。 ([openai.com](https://openai.com/index/introducing-gpt-5-2//?utm_source=openai))\n",
      "- 複数モード（Instant/Thinking/Pro）。Thinkingは推論重視、Proは長時間推論・高品質。 ([openai.com](https://openai.com/index/introducing-gpt-5-2//?utm_source=openai))\n",
      "- GPT-5.2-Codexはコーディング・ソフトウェア開発に特化。 ([openai.com](https://openai.com/index/introducing-gpt-5-2-codex/?utm_source=openai))\n",
      "\n",
      "必要なら公式ページへの案内もします。\n",
      "圧縮後のインプットトークン: 10575\n"
     ]
    }
   ],
   "source": [
    "# これまでの user message + output を compact する\n",
    "compacted = client.responses.compact(\n",
    "    model=\"gpt-5-mini\",\n",
    "    previous_response_id=response.id,\n",
    ")\n",
    "compacted_messages = compacted.output\n",
    "\n",
    "# 次のターンの入力を追加\n",
    "compacted_messages.append({\"role\": \"user\", \"content\": \"さっきGPT-5.2って何に強いって言ってました？\"})\n",
    "\n",
    "# 次に圧縮版で実行\n",
    "compacted_response = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    tools=[{\"type\": \"web_search\"}],\n",
    "    include=[\"reasoning.encrypted_content\", \"web_search_call.action.sources\"],\n",
    "    input=compacted_messages,\n",
    ")\n",
    "\n",
    "print(\"圧縮後の結果:\", compacted_response.output_text)\n",
    "print(\"圧縮後のインプットトークン:\", compacted_response.usage.input_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "context_book",
   "language": "python",
   "name": "context_book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
