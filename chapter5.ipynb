{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c78f6532",
   "metadata": {},
   "source": [
    "### 第5章 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ff36b3",
   "metadata": {},
   "source": [
    "ライブラリのimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d099804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import yaml\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e5e8b5",
   "metadata": {},
   "source": [
    "【注意】下記実行前にREADME.mdに従いルートフォルダにconfig.yamlを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29266156",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as yml:\n",
    "    config = yaml.safe_load(yml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cef04a7",
   "metadata": {},
   "source": [
    "クライアントの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ba7c986",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key = config[\"oai\"][\"key\"], # 取得したAPIキー\n",
    "    # base_url= <URL> # Azure OpenAI Serviceを使う場合は必要\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322f3280",
   "metadata": {},
   "source": [
    "サンプルシナリオ例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcc210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"\n",
    "\n",
    "# Role\n",
    "あなたはコンサルティングファームの週次ニュース調査・事例突合・レポート配信を行うツール駆動エージェントです。\n",
    "<operating_mode>\n",
    "- すべての作業はツール呼び出しで完結する。\n",
    "- 最終出力は必ず send_email の tool call で終了する。\n",
    "</operating_mode>\n",
    "\n",
    "# Task\n",
    "<workflow>\n",
    "Phase1: 入力理解・期間確定\n",
    "Phase2: web_search でニュース収集(複数クエリ)\n",
    "Phase3: 重要度選別・要約・タグ付け\n",
    "Phase4: case_search で社内事例突合\n",
    "Phase5: report_request_approval でレポート生成・承認依頼\n",
    "Phase6: report_request_approval → approved 確認(承認されなければ指摘を反映し再依頼)\n",
    "Phase7: send_email で配信(最終)\n",
    "</workflow>\n",
    "\n",
    "# Input\n",
    "<input_schema>\n",
    "(【略】InputのJSONスキーマとそれぞれのプロパティ説明)\n",
    "</input_schema>\n",
    "\n",
    "# Tool\n",
    "Taskのworkflow内におけるPhaseを思考中に必ず確認し、適切なツールを呼び出して作業を進める。\n",
    "\n",
    "<tool_usage_rules>\n",
    "- 根拠になった情報は検索結果および格納先のURLを[<リンク>]として必ず付与する。\n",
    "</tool_usage_rules>\n",
    "\n",
    "\n",
    "## report_request_approval\n",
    "出力にはreport_template_markdownテンプレートを用いる\n",
    "<report_template_markdown>\n",
    "## サマリ(3〜6行)\n",
    "- (最重要トピックを最大3点)\n",
    "\n",
    "## 今週の重要動向(最大5件)\n",
    "- [重要度: 高/中/低] 見出し\n",
    "\n",
    "## 過去事例との突合(最大5件)\n",
    "- 事例ID/パス: ...\n",
    "\n",
    "## リスク/機会と推奨アクション(最大5件)\n",
    "- (アクションは「誰が/何を/いつまでに」が分かる書き方)\n",
    "\n",
    "## 前提・不確実性(必須)\n",
    "- (推測は推測と明記。未確認は未確認と明記)\n",
    "</report_template_markdown>\n",
    "\n",
    "# Policy\n",
    "<quality_and_grounding>\n",
    "- 根拠のない断定は禁止。日付・数字・固有名詞は特に厳密。\n",
    "- 矛盾があれば追加検索し、解消できなければ不一致として記載。\n",
    "</quality_and_grounding>\n",
    "\n",
    "<privacy_and_handling>\n",
    "- 社内事例DBの詳細を社外共有しない前提で、メール本文は要約＋参照ID/パスに留める。\n",
    "</privacy_and_handling>\n",
    "\"\"\"\n",
    "\n",
    "report_request_approval_description = \"\"\"\n",
    "Purpose: 収集済みニュースと社内事例をもとにレポートMarkdownを生成し、承認依頼として保存・申請します。\n",
    "\n",
    "Use when:\n",
    "- Phase5、および承認が下りなかった場合の再承認依頼時\n",
    "- 対象顧客・期間・想定読者などの前提と必要情報（ニュース要約・事例・推奨アクション）が揃っている\n",
    "\n",
    "Do not use when:\n",
    "- Phase5以外\n",
    "- 収集・分析が未完了で、まず要件や前提条件の確認が必要な状態\n",
    "\n",
    "Notes:\n",
    "- 失敗時: 生成したレポートは保持したまま簡潔に指摘内容を反映し、再試行。\n",
    "\"\"\"\n",
    "\n",
    "report_markdown_description = \"\"\"\n",
    "以下の点を遵守してレポートを作成してください。\n",
    "- レポートはreport_template_markdownテンプレートに従い、冗長な叙述を避ける(箇条書き中心)。\n",
    "- 入力スコープ(顧客・業界・地域・論点・期間)を逸脱しない。\n",
    "- 不足情報は「仮定」として明示。\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3d224e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\"type\": \"web_search\"},\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"report_request_approval\",\n",
    "        \"description\": report_request_approval_description,\n",
    "        \"strict\": True,\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "            \"report_markdown\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": report_markdown_description\n",
    "            }\n",
    "            },\n",
    "            \"required\": [\"report_markdown\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f068519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response_type:  function_call\n",
      "function_name:  report_request_approval\n",
      "argument:  {'report_markdown': '## サマリ(3〜6行)\\n- 自動列車運転（ATO）・自動化の実証実験が複数都市でフェーズ移行しており、短中期で運行コスト低減とサービス拡張が見込まれる（架空）。[ニュースソース: 社内スクレイピング/2025-12-30]\\n- ポストパンデミックの乗客回復は進むが、通勤中心の需要構造変化により運賃収入の構成比が変化、ダイナミックプライシング導入の検討が想定される（架空）。[報告格納先: /internal/rail/market/2025-Q4]\\n- 気候変動に伴う極端気象リスクがインフラ影響を拡大させており、耐候性投資・非常時対応力強化の必要性が高まっている（架空）。[参照: 社内気候レポート/2025-11]\\n\\n## 今週の重要動向(最大5件)\\n- [重要度: 高] 都市鉄道でのATOフェーズ2試験開始 — 時間帯別自動運転拡大と運行最適化のPoCが開始（架空）。[リンク: /news/ato-poc-2025-12-28]\\n- [重要度: 中] 乗客数回復の局所差 — 都市中心部は回復基調だが郊外通勤は未だ低水準で、運賃施策の見直しが必要（架空）。[リンク: /news/ridership-2025-12-25]\\n- [重要度: 中] 輸送需要のモーダルシフト（貨物） — 環境規制とトラック運賃上昇で一部貨物が鉄道へ移行。受け入れインフラ整備がボトルネック（架空）。[リンク: /news/freight-shift-2025-12-20]\\n- [重要度: 中] 車両・半導体供給遅延の継続 — 新型車両導入と設備更新計画に影響（架空）。[リンク: /news/supplychain-2025-12-22]\\n- [重要度: 低] 水素・蓄電池車両の実証進展 — 定期運行に向けた技術検証が進むがコスト課題は残存（架空）。[リンク: /news/h2-battery-2025-12-15]\\n\\n## 過去事例との突合(最大5件)\\n- 事例ID/パス: CASE-RAIL-2022-01: ATO導入支援（某都市鉄道） — PoC設計／安全評価／乗務員再配置案。参照パス: /cases/rail/CASE-RAIL-2022-01（社内閲覧限定）。\\n- 事例ID/パス: CASE-RAIL-2023-07: 複合輸送化プロジェクト（貨物転換） — 駅構内再編と貨物処理の標準化。参照パス: /cases/rail/CASE-RAIL-2023-07。\\n- 事例ID/パス: CASE-RAIL-2024-03: インフラ耐候性強化 — 排水・橋梁補強と非常時復旧計画。参照パス: /cases/rail/CASE-RAIL-2024-03。\\n- 事例ID/パス: CASE-RAIL-2025-09: 電動化・蓄電池試験導入 — 非電化区間の部分電化と蓄電池車両評価。参照パス: /cases/rail/CASE-RAIL-2025-09。\\n\\n## リスク/機会と推奨アクション(最大5件)\\n- 【機会】ATO導入による運行コスト低減とダイヤ柔軟化\\n  - 誰が: 技術戦略部\\n  - 何を: 都市AでのATOフェーズ2 PoC結果を基に、2026年度予算でフェーズ3（本格導入準備）スコープと評価指標を作成\\n  - いつまでに: 2026-03-31\\n- 【リスク/対応】車両・部品供給遅延による設備計画後倒し\\n  - 誰が: 調達部・プロジェクトマネジメント室\\n  - 何を: サプライチェーン・リスク評価を実施し、代替サプライヤーリストと契約柔軟条項を整備\\n  - いつまでに: 2026-02-28\\n- 【機会】貨物モーダルシフトへの参入\\n  - 誰が: 事業開発部\\n  - 何を: 主要荷主向けの試験輸送パッケージを設計し、駅側の荷役改善（短期）を実施\\n  - いつまでに: 2026-06-30\\n- 【リスク】極端気象による運休頻度増加\\n  - 誰が: インフラ運用部\\n  - 何を: 優先度の高い線区での耐候性投資（排水、土留め）リストを作成し、緊急復旧手順を標準化\\n  - いつまでに: 2026-04-30\\n- 【機会】運賃政策の見直しで収入最適化\\n  - 誰が: 収益管理チーム\\n  - 何を: 通勤時間帯の需要データを用いたダイナミックプライシングPoCを設計開始\\n  - いつまでに: 2026-03-31\\n\\n## 前提・不確実性(必須)\\n- 本レポートは架空のニュース・事例を元に作成された想定レポートです。実際の決定や外部展開の際は現地調査・最新データ確認が必須です。\\n- 提示した日付・指標・ケースIDはいずれも社内参照用に架空で付与しています。外部ソースの裏取りは未実施のため未確認事項です。\\n- 見積りは一般的な市場慣行に基づく概算であり、プロジェクト個別の詳細コストは現地条件で大きく変動します。\\n\\n---\\n根拠（架空ソース参照）: [社内ニュースアーカイブ: /news] / [社内事例DB: /cases/rail] / [社内気候レポート: /reports/climate-2025]'}\n",
      "id:  call_Fm9abYrLp53hBLrIwKNnB3ez\n"
     ]
    }
   ],
   "source": [
    "messages=[\n",
    "        {\"role\": \"developer\", \"content\": instruction},\n",
    "        {\"role\": \"user\", \"content\": \"鉄道業界の架空のレポートが出せる状態になった想定で、Phase5に入ったとして、ツール選択してください。レポートは架空のものをそれっぽく作ってください。\"}\n",
    "    ]\n",
    "\n",
    "response = client.responses.create(\n",
    "    instructions=instruction,\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"required\"\n",
    ")\n",
    "\n",
    "response_type = response.output[1].type\n",
    "function_name = response.output[1].name\n",
    "arguments = json.loads(response.output[1].arguments)\n",
    "id = response.output[1].call_id\n",
    "\n",
    "print(\"response_type: \", response_type)\n",
    "print(\"function_name: \", function_name)\n",
    "print(\"argument: \", arguments)\n",
    "print(\"id: \", id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd24aa59",
   "metadata": {},
   "source": [
    "## Reasoning過程の取り出し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927e4042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 会話履歴の格納先を生成\n",
    "conversation = client.conversations.create()\n",
    "\n",
    "# ツール使用結果とReasoning過程を会話履歴に含める設定でLLMにテキスト生成リクエスト\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-5-nano\",\n",
    "  input=[\n",
    "    {\"role\": \"system\", \"content\": \"要求された内容だけ答えてください。\"},\n",
    "    {\"role\": \"user\", \"content\": \"LLMのRAGに関連するキーワードとその簡易解説を1つ出力して。\"}\n",
    "  ],\n",
    "  tools = [\n",
    "    {\"type\": \"web_search\"}\n",
    "  ],\n",
    "  reasoning = {\"summary\":\"detailed\"},\n",
    "  tool_choice=\"required\",\n",
    "  include=[\"web_search_call.action.sources\",  \"reasoning.encrypted_content\"],\n",
    "  conversation=conversation.id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106e08a1",
   "metadata": {},
   "source": [
    "レスポンスの概要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "91e3cb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type\": \"reasoning\",\n",
      "  \"summary\": [\n",
      "    \"**Researching vector database in Japanese**\\n\\nI’m focusing on a keyword related to LLM's RAG. The term \\\"ベクトルデータベース\\\" (vector database) feels appropriate, as it pertains to storing and retrieving high-dimensional vectors used in searches. I plan to provide a simple explanation about how it stores embedding vectors for documents and retrieves related documents using query embeddings with cosine similarity. Since I need to use the web.run tool to find reliable sources, I’ll also consider the citation requirements for supporting statements.\",\n",
      "    \"**Searching for RAG vector database purpose**\\n\\nI’m planning to perform a search for \\\"RAG vector database purpose\\\" or \\\"vector database for RAG.\\\" I want to find reliable sources like academic papers or blogs, including the \\\"RAG: Retrieval-Augmented Generation\\\" paper by Facebook AI, or details about the \\\"Faiss\\\" vector search library. I’ll also aim to site concepts about vector databases storing embeddings for similarity searches. Using web.run, I’ll look for sources with the query \\\"Retrieval-Augmented Generation vector database embedding\\\" to gather support for my findings.\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"type\": \"web_search_call\",\n",
      "  \"query\": \"Retrieval-Augmented Generation vector database embedding\"\n",
      "}\n",
      "{\n",
      "  \"type\": \"reasoning\",\n",
      "  \"summary\": []\n",
      "}\n",
      "{\n",
      "  \"type\": \"message\",\n",
      "  \"role\": \"assistant\",\n",
      "  \"text\": [\n",
      "    \"- キーワード: ベクトルデータベース\\n- 簡易解説: 高次元の埋め込みベクトルを格納・検索するデータベース。RAGでは文書を埋め込み化してベクトルデータベースに格納し、クエリの埋め込みと近似最近傍検索で最も関連性の高い文書を取り出して、LLMの生成にコンテキストとして提供する。 ([en.wikipedia.org](https://en.wikipedia.org/wiki/Vector_database?utm_source=openai))\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for resp in response.output:\n",
    "    # print(resp)\n",
    "    if resp.type == 'reasoning':\n",
    "        print(json.dumps({\"type\": resp.type, \"summary\": [s.text for s in resp.summary]}, ensure_ascii=False, indent=2))\n",
    "    elif resp.type == 'web_search_call':\n",
    "        print(json.dumps({\"type\": resp.type, \"query\": resp.action.query}, ensure_ascii=False, indent=2))\n",
    "    elif resp.type == 'message':\n",
    "        print(json.dumps({\"type\": resp.type, \"role\": resp.role, \"text\": [c.text for c in resp.content if hasattr(c, 'text')]}, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2476042e",
   "metadata": {},
   "source": [
    "conversationへの格納結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a6e3d645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type\": \"message\",\n",
      "  \"role\": \"assistant\",\n",
      "  \"text\": [\n",
      "    \"- キーワード: ベクトルデータベース\\n- 簡易解説: 高次元の埋め込みベクトルを格納・検索するデータベース。RAGでは文書を埋め込み化してベクトルデータベースに格納し、クエリの埋め込みと近似最近傍検索で最も関連性の高い文書を取り出して、LLMの生成にコンテキストとして提供する。 ([en.wikipedia.org](https://en.wikipedia.org/wiki/Vector_database?utm_source=openai))\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"type\": \"reasoning\",\n",
      "  \"summary\": []\n",
      "}\n",
      "{\n",
      "  \"type\": \"web_search_call\",\n",
      "  \"urls\": [],\n",
      "  \"query\": \"Retrieval-Augmented Generation vector database embedding\"\n",
      "}\n",
      "{\n",
      "  \"type\": \"reasoning\",\n",
      "  \"summary\": [\n",
      "    \"**Researching vector database in Japanese**\\n\\nI’m focusing on a keyword related to LLM's RAG. The term \\\"ベクトルデータベース\\\" (vector database) feels appropriate, as it pertains to storing and retrieving high-dimensional vectors used in searches. I plan to provide a simple explanation about how it stores embedding vectors for documents and retrieves related documents using query embeddings with cosine similarity. Since I need to use the web.run tool to find reliable sources, I’ll also consider the citation requirements for supporting statements.\",\n",
      "    \"**Searching for RAG vector database purpose**\\n\\nI’m planning to perform a search for \\\"RAG vector database purpose\\\" or \\\"vector database for RAG.\\\" I want to find reliable sources like academic papers or blogs, including the \\\"RAG: Retrieval-Augmented Generation\\\" paper by Facebook AI, or details about the \\\"Faiss\\\" vector search library. I’ll also aim to site concepts about vector databases storing embeddings for similarity searches. Using web.run, I’ll look for sources with the query \\\"Retrieval-Augmented Generation vector database embedding\\\" to gather support for my findings.\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"type\": \"message\",\n",
      "  \"role\": \"user\",\n",
      "  \"text\": [\n",
      "    \"LLMのRAGに関連するキーワードとその簡易解説を1つ出力して。\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"type\": \"message\",\n",
      "  \"role\": \"system\",\n",
      "  \"text\": [\n",
      "    \"要求された内容だけ答えてください。\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "items = client.conversations.items.list(conversation.id, limit=10)\n",
    "\n",
    "for item in items.data:\n",
    "    # print(item)\n",
    "    if item.type == 'reasoning':\n",
    "        print(json.dumps({\"type\": item.type, \"summary\": [s.text for s in item.summary] if hasattr(item, 'summary') else []}, ensure_ascii=False, indent=2))\n",
    "    elif item.type == 'web_search_call':\n",
    "        sources = getattr(item.action, \"sources\", None) if hasattr(item, 'action') else None\n",
    "        print(json.dumps({\n",
    "            \"type\": item.type,\n",
    "            \"urls\": [src.url for src in sources] if sources else [],\n",
    "            \"query\": getattr(item.action, \"query\", None) if hasattr(item, 'action') else None\n",
    "        }, ensure_ascii=False, indent=2))\n",
    "    elif item.type == 'message':\n",
    "        print(json.dumps({\"type\": item.type, \"role\": item.role, \"text\": [c.text for c in item.content if hasattr(c, 'text')]}, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee0212",
   "metadata": {},
   "source": [
    "reasoning itemだけを削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e5ac2c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type\": \"message\",\n",
      "  \"text\": [\n",
      "    \"- キーワード: ベクトルデータベース\\n- 簡易解説: 高次元の埋め込みベクトルを格納・検索するデータベース。RAGでは文書を埋め込み化してベクトルデータベースに格納し、クエリの埋め込みと近似最近傍検索で最も関連性の高い文書を取り出して、LLMの生成にコンテキストとして提供する。 ([en.wikipedia.org](https://en.wikipedia.org/wiki/Vector_database?utm_source=openai))\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"type\": \"web_search_call\",\n",
      "  \"urls\": [],\n",
      "  \"query\": \"Retrieval-Augmented Generation vector database embedding\"\n",
      "}\n",
      "{\n",
      "  \"type\": \"message\",\n",
      "  \"text\": [\n",
      "    \"LLMのRAGに関連するキーワードとその簡易解説を1つ出力して。\"\n",
      "  ]\n",
      "}\n",
      "{\n",
      "  \"type\": \"message\",\n",
      "  \"text\": [\n",
      "    \"要求された内容だけ答えてください。\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "reasoning_msg_ids = [itm.id for itm in items.data if itm.type == \"reasoning\"]\n",
    "\n",
    "for msg_id in reasoning_msg_ids:\n",
    "   new_conversation = client.conversations.items.delete(conversation_id=conversation.id, item_id=msg_id)\n",
    "\n",
    "items = client.conversations.items.list(new_conversation.id, limit=10)\n",
    " \n",
    "for item in items.data:\n",
    "    # print(item)\n",
    "    if item.type == 'reasoning':\n",
    "        print(json.dumps({\"type\": item.type, \"summary\": [s.text for s in item.summary] if hasattr(item, 'summary') else []}, ensure_ascii=False, indent=2))\n",
    "    elif item.type == 'web_search_call':\n",
    "        sources = getattr(item.action, \"sources\", None) if hasattr(item, 'action') else None\n",
    "        print(json.dumps({\n",
    "            \"type\": item.type,\n",
    "            \"urls\": [src.url for src in sources] if sources else [],\n",
    "            \"query\": getattr(item.action, \"query\", None) if hasattr(item, 'action') else None\n",
    "        }, ensure_ascii=False, indent=2))\n",
    "    elif item.type == 'message':\n",
    "        print(json.dumps({\"type\": item.type, \"text\": [c.text for c in item.content if hasattr(c, 'text')]}, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdbfa20",
   "metadata": {},
   "source": [
    "会話履歴の圧縮"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c642dae",
   "metadata": {},
   "source": [
    "###### ※この例ではサンプルが小さいため、圧縮しても効果が薄いor元よりもトークンが大きくなる点に注意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "74521d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "結果: 最新は Gemini 3。Pro/Deep Think、Ultraはプラン別。 ([blog.google](https://blog.google/products/gemini/gemini-3/?utm_source=openai))\n"
     ]
    }
   ],
   "source": [
    "# ダミーの会話を用意\n",
    "messages = [\n",
    "    {\"role\":\"system\",\"content\":\"あなたはLLMの専門家です。具体情報を交えて短め(最大50字程度)で答えてください。\"},\n",
    "    {\"role\":\"user\",\"content\":\"私は中学生です。GPT-5.2とGPT-4.1の位置づけを、用途別に教えてください。\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"GPT-5.2は推論対応の旗艦で、複雑なコーディングやエージェントに強いです。\"},\n",
    "    {\"role\":\"user\",\"content\":\"低コスト重視で遅延も抑えたいとき、GPT-5系はどう選びますか。\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"GPT-5 miniは速く安価で定型タスク向きで、さらに軽量ならGPT-5 nanoが候補です。\"},\n",
    "    {\"role\":\"user\",\"content\":\"長文を大量に扱う場合、推論なしで高文脈の選択肢はありますか。\"},\n",
    "    {\"role\":\"assistant\",\"content\":\"推論ステップ不要ならGPT-4.1が約1M文脈で有力で、難問はGPT-5系も併用します。\"},\n",
    "    {\"role\":\"user\",\"content\":\"最新のモデルはGoogleだと何だろう？調べてくれる？\"}\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    tools=[{\"type\": \"web_search\"}],\n",
    "    include=[\"reasoning.encrypted_content\", \"web_search_call.action.sources\"],\n",
    "    input=messages,\n",
    "    store=True\n",
    ")\n",
    "\n",
    "print(\"結果:\", response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f6060cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "非圧縮の結果: 推論対応の旗艦で、複雑なコーディングやエージェントに強いです。\n",
      "非圧縮のインプットトークン: 4962\n"
     ]
    }
   ],
   "source": [
    "# まずは非圧縮版で実行\n",
    "normal_response = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    tools=[{\"type\": \"web_search\"}],\n",
    "    include=[\"reasoning.encrypted_content\", \"web_search_call.action.sources\"],\n",
    "    previous_response_id=response.id,\n",
    "    input=[{\"role\": \"user\", \"content\": \"さっきGPT-5.2って何に強いって言ってました？\"}],\n",
    ")\n",
    "print(\"非圧縮の結果:\", normal_response.output_text)\n",
    "print(\"非圧縮のインプットトークン:\", normal_response.usage.input_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2a77d6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hirosatogamo\\.virtualenvs\\pipenv-slS7I_su\\Lib\\site-packages\\pydantic\\main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `literal['output_text']` - serialized value may not be as expected [field_name='type', input_value='input_text', input_type=str])\n",
      "  PydanticSerializationUnexpectedValue(Expected `ResponseOutputRefusal` - serialized value may not be as expected [field_name='content', input_value=ResponseOutputText(annota...ut_text', logprobs=None), input_type=ResponseOutputText])\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "圧縮後の結果: 最新情報に基づく要点だけをお伝えします。GPT-5.2は公式発表によると、以下の領域で従来モデルより強化されています（2025年12月頃のリリース、一般利用はChatGPTとAPIで順次提供開始）。\n",
      "\n",
      "- 汎用的な生産性・タスク処理の向上\n",
      "  - スプレッドシート作成、プレゼンテーション作成、コード作成、画像の理解、長い文脈の理解、ツールの活用、複雑で多段階のプロジェクトの処理能力が向上。これらは日常的な業務ワークフロー全体での効率化を狙っています。 ([openai.com](https://openai.com/index/introducing-gpt-5-2//?utm_source=openai))\n",
      "\n",
      "- 長文・長文ドキュメントの処理能力（長文推論と統合）\n",
      "  - 長文コンテキスト推論で新しい水準を達成し、実務データの深い分析・統合が可能になるとしています。 MRCR v2 の評価で256kトークン相当の長文でも高い精度を示すとされています。実務での深い分析・多ソースの統合に適しています。 ([openai.com](https://openai.com/index/introducing-gpt-5-2//?utm_source=openai))\n",
      "\n",
      "- ツール呼び出しと複数アクションの統合（エージェント的運用）\n",
      "  - 複数のツールを横断して使うワークフローの安定性と効率が向上。 Tau2-bench Telecomでのツール活用が高精度（約98.7%）に達するなど、長い対話・複数ステップのタスクでの信頼性が改善されています。 ([openai.com](https://openai.com/index/introducing-gpt-5-2//?utm_source=openai))\n",
      "\n",
      "- コード生成・エージェント的能力の強化（GPT-5.2-Codex など）\n",
      "  - エージェント的なコード作成や大規模なコード変更・リファクタリング、Windows環境でのパフォーマンス改善など、専門的な開発領域での能力が向上。コード関連のタスクで特に強化されています。 ([openai.com](https://openai.com/index/introducing-gpt-5-2-codex/?utm_source=openai))\n",
      "\n",
      "- 安全性・信頼性の改善\n",
      "  - 敏感な話題や安全性を要する場面での応答品質が改善され、全体的な信頼性が向上しています。 ([openai.com](https://openai.com/index/introducing-gpt-5-2//?utm_source=openai))\n",
      "\n",
      "- 知識のアップデートと現実世界の理解\n",
      "  - August 2025の知識カットオフを前提に、現行のツールやトレンドへの適応性が高く、現実世界の最新情報に対する理解が強化されています。 ([academy.openai.com](https://academy.openai.com/public/resources/latest-model?utm_source=openai))\n",
      "\n",
      "- 利用形態とエコシステムの拡張\n",
      "  - チャット（ChatGPT）では Instant / Thinking / Pro の各モデルから選択可能、API側でも gpt-5.2 系列として提供され、Reasoning のオプションや新しいモードが利用可能です。 ([openai.com](https://openai.com/index/introducing-gpt-5-2//?utm_source=openai))\n",
      "\n",
      "補足\n",
      "- GPT-5.2は「GPT-5」シリーズの中で smartest かつ work向けの知能・生産性を大幅に強化したアップデートとして位置づけられています。Codex系の派生も用意され、特に業務・開発・データ分析の現場での適用が強調されています。 ([openai.com](https://openai.com/index/introducing-gpt-5-2//?utm_source=openai))\n",
      "\n",
      "もし用途別に“どのGPT-5.2系を選ぶべきか”を具体的に知りたい場合（例：低遅延志向、長文分析、コード中心、画像理解など）、用途を教えてください。用途別のおすすめと、比較すべき点も整理してお伝えします。\n",
      "圧縮後のインプットトークン: 10462\n"
     ]
    }
   ],
   "source": [
    "# これまでの user message + output を compact する\n",
    "compacted = client.responses.compact(\n",
    "    model=\"gpt-5-mini\",\n",
    "    previous_response_id=resp.id,\n",
    ")\n",
    "compacted_messages = compacted.output\n",
    "\n",
    "# 次のターンの入力を追加\n",
    "compacted_messages.append({\"role\": \"user\", \"content\": \"さっきGPT-5.2って何に強いって言ってました？\"})\n",
    "\n",
    "# 次に圧縮版で実行\n",
    "compacted_response = client.responses.create(\n",
    "    model=\"gpt-5-nano\",\n",
    "    tools=[{\"type\": \"web_search\"}],\n",
    "    include=[\"reasoning.encrypted_content\", \"web_search_call.action.sources\"],\n",
    "    input=compacted_messages,\n",
    ")\n",
    "\n",
    "print(\"圧縮後の結果:\", compacted_response.output_text)\n",
    "print(\"圧縮後のインプットトークン:\", compacted_response.usage.input_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289327e2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "context_book",
   "language": "python",
   "name": "context_book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
