{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d099804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import yaml\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29266156",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as yml:\n",
    "    config = yaml.safe_load(yml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ba7c986",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key = config[\"oai\"][\"key\"], # 取得したAPIキー\n",
    "    # base_url= <URL> # Azure OpenAI Serviceを使う場合は必要\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "762f18a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"web_search\",\n",
    "        \"description\": \"指定された複数のクエリでWeb検索を行い、各結果を要約して返します。\",        \n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"queries\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"string\"\n",
    "                    },\n",
    "                    \"description\": \"検索するクエリ文字列のリスト\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"queries\"]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ca94937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argument: \n",
      "{\n",
      "  \"step_back\": \"Azure上でOpenAI系（GPT）を使う方法と、AWS上でLLM（Bedrock/SageMaker/セルフホスティング）を使う方法を機能・運用・コスト・セキュリティなどの観点で比較したいという意図。\",\n",
      "  \"background_knowledge\": \"比較のために押さえるべき背景知識：\\n- AzureはOpenAIと提携しAzure OpenAI Service（Azure AI Studio含む）でGPT系モデルをマネージドで提供。モデルバージョン、利用制限、リージョンごとの可用性、VNet/Private Link、Enterprise契約やデータ取り扱い協定が重要。\\n- AWSはBedrockで複数のファウンデーションモデル（Anthropic, Cohere, AI21, Amazon Titan等）をマネージド提供、SageMakerでは任意モデルのトレーニング/デプロイが可能。セルフホストやコンテナ化（ECR/ECS/EKS/EC2 GPU）での柔軟性が高い。\\n- カスタマイズ手段：マネージドの微調整（Fine-tuning）、プロンプトデザイン、ファインチューニング代替（RL, LoRA）、プライベートエンドポイントやオンプレ/エッジでのデプロイが比較軸。\\n- 検索・RAG連携：Azure Cognitive SearchやAmazon Kendra/OpenSearch + k-NN、外部ベクタDB（Pinecone, Milvus, Weaviate）との統合とコスト。\\n- 運用面：スケーリング（オートスケーリング）、デプロイ費用（インスタンス料金 vs リクエスト課金）、監視・ログ（Azure Monitor, CloudWatch）、モデルガバナンス、監査証跡。\\n- セキュリティ・コンプライアンス：VNet/PrivateLink、KMSによる暗号化、SOC/ISO/HIPAA等認証対応、データ保持と使用に関するプロバイダーポリシー。\\n- 価格体系：トークン課金（OpenAI系）やリクエスト/時間課金（Bedrock/SageMaker）、インフラ（GPUインスタンス）コストの違い。\\n- レイテンシとリージョン：リージョンとエッジ要件が遅延に与える影響。\\n\\n検索クエリ（日本語の文章で複数）：\\n1. \\\"Azure OpenAI Service の提供モデルとサポートされている GPT バージョン一覧とリージョン別可用性\\\"\\n2. \\\"Azure AI Studio でのカスタム GPT 作成とファインチューニングの方法と制限事項\\\"\\n3. \\\"Azure Cognitive Search と OpenAI embeddings を組み合わせた RAG 実装のベストプラクティス\\\"\\n4. \\\"Amazon Bedrock で利用可能なファウンデーションモデル一覧と利用料金の最新情報\\\"\\n5. \\\"AWS SageMaker を使った大規模言語モデルのデプロイ（推論エンドポイント/サーバーレス/コンテナ）の比較ガイド\\\"\\n6. \\\"AWS でオープンソース LLM（Llama, Mistral 等）をセルフホストする際のコスト試算とベストプラクティス\\\"\\n7. \\\"Azure と AWS の OpenAI/Bedrock サービスにおけるセキュリティ（VNet/PrivateLink, KMS, データ保持）差異\\\"\\n8. \\\"Azure OpenAI と AWS Bedrock の課金モデル（トークン課金 vs インスタンス/リクエスト課金）比較例\\\"\\n9. \\\"企業向けコンプライアンス（SOC/HIPAA/ISO）における Azure OpenAI と AWS Bedrock/SageMaker の対応状況\\\"\\n10. \\\"Azure と AWS の MLOps ツール（Azure ML, SageMaker Pipelines）を使った LLM 運用のワークフロー比較\\\"\\n11. \\\"Azure で GPT を使うときのレイテンシとスケーリングの実践例とベストプラクティス\\\"\\n12. \\\"AWS で RAG を構築する際の Amazon Kendra と OpenSearch + ベクタDB の使い分け\\\"\\n13. \\\"Azure OpenAI の利用規約とデータ利用ポリシーの企業向け確認ポイント\\\"\\n14. \\\"AWS Bedrock のモデル選択基準と各モデルの強み・弱みの比較\\\"\\n\\nこれらの出力を使ってドキュメント検索／RAG パイプラインで最新情報を収集するとよい。必要なら、詳細な検索クエリや実際のドキュメントの抜粋取得も支援します。  \",\n",
      "  \"queries\": [\n",
      "    \"Azure OpenAI Service の提供モデルとサポートされている GPT バージョン一覧とリージョン別可用性\",\n",
      "    \"Azure AI Studio でのカスタム GPT 作成とファインチューニングの方法と制限事項\",\n",
      "    \"Azure Cognitive Search と OpenAI embeddings を組み合わせた RAG 実装のベストプラクティス\",\n",
      "    \"Amazon Bedrock で利用可能なファウンデーションモデル一覧と利用料金の最新情報\",\n",
      "    \"AWS SageMaker を使った大規模言語モデルのデプロイ（推論エンドポイント/サーバーレス/コンテナ）の比較ガイド\",\n",
      "    \"AWS でオープンソース LLM（Llama, Mistral 等）をセルフホストする際のコスト試算とベストプラクティス\",\n",
      "    \"Azure と AWS の OpenAI/Bedrock サービスにおけるセキュリティ（VNet/PrivateLink, KMS, データ保持）差異\",\n",
      "    \"Azure OpenAI と AWS Bedrock の課金モデル（トークン課金 vs インスタンス/リクエスト課金）比較例\",\n",
      "    \"企業向けコンプライアンス（SOC/HIPAA/ISO）における Azure OpenAI と AWS Bedrock/SageMaker の対応状況\",\n",
      "    \"Azure と AWS の MLOps ツール（Azure ML, SageMaker Pipelines）を使った LLM 運用のワークフロー比較\",\n",
      "    \"Azure で GPT を使うときのレイテンシとスケーリングの実践例とベストプラクティス\",\n",
      "    \"AWS で RAG を構築する際の Amazon Kendra と OpenSearch + ベクタDB の使い分け\",\n",
      "    \"Azure OpenAI の利用規約とデータ利用ポリシーの企業向け確認ポイント\",\n",
      "    \"AWS Bedrock のモデル選択基準と各モデルの強み・弱みの比較\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "tool_def = [\n",
    "  { \n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"generate_rag_search_components\",\n",
    "    \"description\": \"ユーザ入力に基づき、RAG（検索拡張生成）のためのステップバック、関連知識、および検索クエリを生成する。\",\n",
    "    \"parameters\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\n",
    "        \"step_back\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"ユーザ要求を一段抽象化し、意図を明確にする簡潔な再定式化です。\"\n",
    "        },\n",
    "        \"background_knowledge\": {\n",
    "          \"type\": \"string\",\n",
    "          \"description\": \"より効果的な検索クエリを作成するために役立つドメイン知識または常識です。\"\n",
    "        },\n",
    "        \"queries\": {\n",
    "          \"type\": \"array\",\n",
    "          \"items\": {\n",
    "            \"type\": \"string\"\n",
    "          },\n",
    "          \"description\": \"ユーザ要求に関連する情報を取得するための検索エンジン用クエリ文のリストです。キーワードではなく日本語の文章のリストで生成します。必要に応じて複数のクエリを生成してください。\"\n",
    "          \n",
    "        }\n",
    "      },\n",
    "      \"required\": [\"step_back\", \"background_knowledge\", \"queries\"]\n",
    "    }\n",
    "  }\n",
    "]\n",
    "\n",
    "question = \"AzureでGPTを使う方法とAWSでLLMを使う方法の比較をしたい。\"\n",
    "\n",
    "messages=[\n",
    "        {\"role\": \"system\", \"content\": \"適宜ツールを使ってユーザに回答してください。\"},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=messages,\n",
    "    tools=tool_def,\n",
    "    tool_choice={\"type\":\"function\",\"name\":\"generate_rag_search_components\"}, # 実験のため呼び出すツールを強制\n",
    ")\n",
    "\n",
    "arguments = response.output[1].arguments\n",
    "\n",
    "print(\"argument: \")\n",
    "print(json.dumps(json.loads(arguments), indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "614e018d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseReasoningItem(id='rs_00b2ea661abbf3a6006946e01681108194bf51c6393b4840b5', summary=[], type='reasoning', content=None, encrypted_content=None, status=None),\n",
       " ResponseOutputMessage(id='msg_00b2ea661abbf3a6006946e02546488194ba19f27821b563fd', content=[ResponseOutputText(annotations=[], text='いい比較ですね。以下は「AzureでGPTを使う（主に Azure OpenAI Service）」と「AWSでLLMを使う（主に Amazon Bedrock / SageMaker を想定）」の主要な違い・特徴を整理したものです。導入判断に使えるチェックリストと典型的なアーキテクチャ例も付けます。\\n\\n要約（結論）\\n- すぐにOpenAI系（GPT）モデルを使い、Microsoftエコシステム（Azure AD、M365、Power Platform）と強く連携したい → Azure OpenAI Serviceが自然な選択。\\n- 複数ベンダーのファウンデーションモデル（Anthropic/Meta/Cohere/独自モデル/AWS Titan 等）を比較利用したい、または自分で大モデルをトレーニング/ホストしたい → AWS（Bedrock + SageMaker）の方が柔軟性が高い。\\n\\n比較ポイント\\n\\n1) 提供サービスとモデルの選択肢\\n- Azure\\n  - 主に Azure OpenAI Service 経由でOpenAIのモデル（GPT-3.5/GPT-4系、embeddingsなど）を提供。\\n  - Azure AI Studio による管理 GUI、デプロイ、テスト、プロンプト管理など。\\n  - Microsoft のCognitive Servicesと統合可能。\\n- AWS\\n  - Amazon Bedrock：複数ベンダーのファウンデーションモデル（Anthropic, Cohere, Mistral等）＋AWSのTitanをマネージドで提供（モデルの選択肢が豊富）。\\n  - Amazon SageMaker：学習、微調整、ホスティング（自前モデルをトレーニング→デプロイするワークフローに向く）。\\n  - EC2/GPU（自ホスティング）やECS/EKSでのコンテナ化も可能。\\n\\n2) マネージド性とデプロイ方式\\n- Azure：OpenAIモデルはMicrosoftがホストするマネージドAPI。自前でモデルをホストするより運用負荷が低い。VNet/private endpointやKey Vault統合でセキュアに使える。\\n- AWS：BedrockはマネージドAPIで即利用可。SageMakerは学習→微調整→ホスティングまで含む（カスタムや大規模トレーニングに強い）。自前ホストの自由度高い。\\n\\n3) セキュリティ・ネットワーク・ガバナンス\\n- Azure\\n  - Azure AD（Entra）による認証・RBAC、Private Endpoint（Private Link）、Key Vaultで鍵管理。\\n  - M365 / Defender 等と連携しやすく、Microsoftのコンプライアンス体系（ISO、SOC、HIPAA 等）に準拠したオプションあり。\\n- AWS\\n  - IAMポリシー、STS、KMS（鍵管理）、VPCエンドポイント（PrivateLink）でセキュリティ設計可能。\\n  - ガバナンスはIAM + Organizations + Service Control Policiesで細かく制御できる。\\n\\n4) カスタマイズ／微調整（fine-tuning）と拡張性\\n- Azure\\n  - プロンプト設計、システム指示、少量のカスタマイズが主。モデルのフル微調整はOpenAI/Azureのサポート方法に依存（提供状況は随時変わる）。\\n- AWS\\n  - SageMaker でフル微調整（学習ジョブ）や大規模なカスタムモデル運用が可能。Bedrockでも「モデルカスタマイズ」や少量データでの適応（プロンプトチューニング的機能）を提供する場合がある。\\n\\n5) 統合性（他クラウドサービスとのつながり）\\n- Azure\\n  - Azure Functions, Logic Apps, Power Platform, Microsoft 365 と密に統合可能。エンタープライズの既存Microsoft利用者には利便性が高い。\\n- AWS\\n  - S3（データストレージ）、Lambda、API Gateway、Kinesis、CloudWatch 等と自然に連携。データパイプライン／ETLならAWSスタックで完結しやすい。\\n\\n6) 認証・APIの呼び出し方式\\n- Azure：Azureのエンドポイント + APIキーかAzure ADトークン。SDK（Azure SDK）やHTTPで利用。\\n- AWS：AWS SDKやREST（署名付きリクエスト）でIAM認証。RoleやSTSで細かく権限設定。\\n\\n7) ネットワークレイテンシ・リージョン\\n- 両者とも主要リージョンで利用可能。レイテンシはリージョン選択・VPC/PrivateLink構成・プロキシ経路で左右されるため、近いリージョンを選ぶのが重要。\\n\\n8) 価格\\n- モデル・呼び出し回数・トークン数・実行時間・推論インスタンスで変わる。\\n- Azure：API利用（モデル別トークン課金）。エンタープライズ契約で割引や専用リソースも。\\n- AWS：Bedrockはモデル別料金、SageMakerは学習/推論のインスタンスごとの実行時間課金。S3/データ転送等の周辺コストも考慮。\\n- どちらも高頻度・大規模利用では設計次第でコストが大きく変わるため、トークン制限、キャッシュ、バッチ処理、低レイテンシ要件のための専用インスタンス等を検討。\\n\\n9) 観測性・運用\\n- Azure：Azure Monitor, Application Insights, Log Analytics と連携。\\n- AWS：CloudWatch、SageMaker Debugger、X-Ray 等でモニタリング・トレーシングが可能。\\n\\n10) 法務・データ利用ポリシー\\n- Azure OpenAI はデータ処理や利用に関してMicrosoftとOpenAIのポリシーが適用される（データ保持ポリシーや利用制限を確認）。企業の機密データを送る場合はデータ処理条項を要確認。\\n- AWS Bedrock はモデルベンダーごとにデータ利用ポリシーが異なる。機密データをサードパーティモデルへ送る場合は注意、または専用モデル（オンプレやSageMakerでの自ホスト）を検討。\\n\\n典型的なアーキテクチャ（簡易）\\n- Azure（OpenAIをAPIとして利用する例）\\n  1. クライアント → Azure API Management（APIゲートウェイ） → Azure Function / App Service（ビジネスロジック）\\n  2. Azure Function が Azure OpenAI Service を呼び出し（KeyVaultに鍵保管、Private Endpointを通す）\\n  3. 検索用のデータは Azure Cognitive Search（RAG） + Azure Blob Storage／Cosmos DB\\n  4. ログは Log Analytics / Application Insights に送る\\n- AWS（BedrockまたはSageMakerを使う例）\\n  1. クライアント → API Gateway / ALB → Lambda / ECS（ビジネスロジック）\\n  2. Lambda が Bedrock API または SageMaker エンドポイントを呼び出し（Secrets Managerでクレデンシャル、VPCエンドポイントでプライベート接続）\\n  3. RAG 用に S3 + OpenSearch（あるいはRDS）、埋め込みは Bedrock/SageMakerで生成\\n  4. 監視は CloudWatch、トレーシングは X-Ray\\n\\n導入判断のチェックリスト（質問）\\n- 既にどちらのクラウドを主に使っているか？（既存投資を重視）\\n- 必要なモデルは特定のベンダーに依存するか？（OpenAI GPTが必須か、多様なFMが必要か）\\n- 機密データを外部モデルへ送ることに法的/コンプライアンス上の制約はあるか？\\n- カスタム学習（大規模微調整）を行う予定はあるか？（ある → SageMakerの方が有利）\\n- レイテンシや地域固有のデータ居住要件はあるか？\\n- 予算感（長期的に大量推論するか）とコスト最適化手段（キャッシュ、オンプレGPUなど）は？\\n\\n短い推奨\\n- すぐにGPT（OpenAI）を組み込み、Microsoft製ツールと連携したい：Azure OpenAI Service。\\n- 複数モデルを比較したい、大規模カスタム学習やオンプレ寄せの柔軟性が必要：AWS（Bedrock＋SageMaker）。\\n- セキュリティとデータ所在が最優先で、自社で完全管理したい：SageMaker/EC2で自ホストやAWS Outpostsを検討。\\n\\n必要なら次にやること（提案）\\n1. 要件整理シート作成（必要なモデル、QPS、レイテンシ、法務要件、既存インフラ）。\\n2. Proof of Concept：各クラウドで同じユースケース（同一プロンプト・データ）を1週間で試し、レスポンス品質・コストを比較。\\n3. セキュリティレビュー（データフロー、DLP、同意/契約の確認）。\\n4. 運用設計（監視、コストアラート、スケール戦略）。\\n\\nもしよければ、あなたのユースケース（例：チャットボット、ドキュメント検索、生成系API、高頻度バッチ推論 等）を教えてください。それに合わせて「具体的な構成図」「見積りに必要なパラメータ」「PoC プラン（手順・チェックポイント）」を提示します。', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635da8f1",
   "metadata": {},
   "source": [
    "PDFのhtml化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11d90058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF を読み込み中: reference\\RAG_Sample_Doc.pdf\n",
      "  - ページ 1 を変換\n",
      "  - ページ 2 を変換\n",
      "HTML 変換が完了しました: result\\pdf2html\\RAG_Sample_Doc.html\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# pip install pymupdf\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def pdf_to_html(\n",
    "    input_pdf: str | Path,\n",
    "    output_html: str | Path,\n",
    "    *,\n",
    "    standalone: bool = True\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    PDF を HTML に変換して保存する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_pdf : str | Path\n",
    "        入力 PDF ファイル\n",
    "    output_html : str | Path\n",
    "        出力 HTML ファイル\n",
    "    standalone : bool\n",
    "        <!DOCTYPE html> 付きの完全な文書にするかどうか\n",
    "    \"\"\"\n",
    "    input_pdf = Path(input_pdf)\n",
    "    output_html = Path(output_html)\n",
    "\n",
    "    if not input_pdf.exists():\n",
    "        raise FileNotFoundError(f\"入力PDFが見つかりません: {input_pdf}\")\n",
    "\n",
    "    print(f\"PDF を読み込み中: {input_pdf}\")\n",
    "    doc = fitz.open(input_pdf)\n",
    "\n",
    "    html_parts: list[str] = []\n",
    "    for page_num, page in enumerate(doc, start=1):\n",
    "        html_parts.append(page.get_text(\"html\"))\n",
    "        print(f\"  - ページ {page_num} を変換\")\n",
    "\n",
    "    # HTML ドキュメントを構築\n",
    "    if standalone:\n",
    "        html = \"<!DOCTYPE html>\\n<html>\\n<body>\\n\" + \"\\n\".join(html_parts) + \"\\n</body>\\n</html>\"\n",
    "    else:\n",
    "        html = \"\\n\".join(html_parts)\n",
    "\n",
    "    # 出力ディレクトリを作成\n",
    "    output_html.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 保存\n",
    "    with output_html.open(\"w\", encoding=\"utf-8\", newline=\"\\n\") as f:\n",
    "        f.write(html)\n",
    "\n",
    "    print(f\"HTML 変換が完了しました: {output_html}\")\n",
    "\n",
    "\n",
    "# ------------------ 実行例 ------------------\n",
    "if __name__ == \"__main__\":\n",
    "    INPUT_PDF = Path(\"./reference/RAG_Sample_Doc.pdf\")\n",
    "    OUTPUT_HTML = Path(\"./result/pdf2html/RAG_Sample_Doc.html\")\n",
    "\n",
    "    pdf_to_html(INPUT_PDF, OUTPUT_HTML)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea5f243",
   "metadata": {},
   "source": [
    "Wordドキュメントのhtml化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "715ab59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力ファイル確認: ./reference/RAG_Sample_Doc.docx\n",
      "Pandoc reader オプション: --extract-media=c:\\Users\\hirosatogamo\\iCloudDrive\\hiro_project\\prompt_book\\code\\result\\word2html\\media\n",
      "Pandoc writer オプション: ['--standalone']\n",
      "抽出されたメディアファイル数: 2\n",
      "  - result\\word2html\\media\\media\\image1.png\n",
      "HTML 変換が完了しました。\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandoc  # pip install pandoc\n",
    "\n",
    "def docx_to_html(\n",
    "    input_path: str | Path,\n",
    "    output_path: str | Path | None = None,\n",
    "    *,\n",
    "    standalone: bool = True,\n",
    "    extract_media_dir: str | Path | None = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    DOCX を HTML に変換する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_path : str | Path\n",
    "        入力 .docx ファイル\n",
    "    output_path : str | Path | None\n",
    "        出力 HTML ファイル名。None の場合は文字列を返すだけ。\n",
    "    standalone : bool\n",
    "        HTML を <!DOCTYPE html> 付きの完全な文書にするかどうか。\n",
    "    extract_media_dir : str | Path | None\n",
    "        画像などを外部ファイルとして保存したい場合の取り出し先ディレクトリ (--extract-media)。\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        生成された HTML（output_path を与えた場合でも文字列を返す）\n",
    "    \"\"\"\n",
    "    # 1. 読み込み時のオプション（--extract-media は reader 専用）\n",
    "    reader_opts: list[str] = []\n",
    "    if extract_media_dir:\n",
    "        abs_media_dir = os.path.abspath(extract_media_dir)\n",
    "        reader_opts.append(f\"--extract-media={abs_media_dir}\")\n",
    "        print(f\"Pandoc reader オプション: --extract-media={abs_media_dir}\")\n",
    "\n",
    "    # 2. 読み込み\n",
    "    doc = pandoc.read(file=input_path, format=\"docx\", options=reader_opts)\n",
    "\n",
    "    # 3. 書き出し時のオプション\n",
    "    writer_opts: list[str] = []\n",
    "    if standalone:\n",
    "        writer_opts.append(\"--standalone\")\n",
    "    print(f\"Pandoc writer オプション: {writer_opts}\")\n",
    "\n",
    "    # 4. 書き出し\n",
    "    html = pandoc.write(\n",
    "        doc,\n",
    "        file=output_path,   # None なら戻り値のみ\n",
    "        format=\"html\",\n",
    "        options=writer_opts\n",
    "    )\n",
    "\n",
    "    # 5. メディアファイルの確認\n",
    "    if extract_media_dir:\n",
    "        media_files = list(Path(extract_media_dir).rglob(\"*\"))\n",
    "        print(f\"抽出されたメディアファイル数: {len(media_files)}\")\n",
    "        for f in media_files:\n",
    "            if f.is_file():\n",
    "                print(f\"  - {f}\")\n",
    "\n",
    "    return html\n",
    "\n",
    "\n",
    "# ------------- 使い方例 -------------\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"./reference/RAG_Sample_Doc.docx\"\n",
    "    if not os.path.exists(input_file):\n",
    "        print(f\"入力ファイルが見つかりません: {input_file}\")\n",
    "    else:\n",
    "        print(f\"入力ファイル確認: {input_file}\")\n",
    "\n",
    "    html_text = docx_to_html(\n",
    "        input_file,\n",
    "        output_path=\"result/word2html/RAG_Sample_Doc.html\",\n",
    "        extract_media_dir=\"result/word2html/media\"\n",
    "    )\n",
    "    print(\"HTML 変換が完了しました。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ed3b52",
   "metadata": {},
   "source": [
    "htmlをTableのみ保持したMarkdown形式へ変換するサンプル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7476ec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "from bs4 import BeautifulSoup, Comment, NavigableString, Tag\n",
    "from markdownify import markdownify as md\n",
    "\n",
    "INPUT_HTML = Path(\"./result/word2html/RAG_Sample_Doc.html\")\n",
    "OUTPUT_MD_DIR = Path(\"./result/html2markdown\")\n",
    "OUTPUT_MD = OUTPUT_MD_DIR / \"RAG_Sample_Doc.md\"\n",
    "\n",
    "TABLE_TOKEN_TEMPLATE = \"§§TABLE{idx}§§\"\n",
    "\n",
    "\n",
    "def load_html(path: Path) -> BeautifulSoup:\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        return BeautifulSoup(f.read(), \"html.parser\")\n",
    "\n",
    "\n",
    "def remove_css_and_related_attrs(soup: BeautifulSoup) -> None:\n",
    "    # <style> と <link rel=\"stylesheet\"> を削除\n",
    "    for style_tag in soup.find_all(\"style\"):\n",
    "        style_tag.decompose()\n",
    "    for link_tag in soup.find_all(\"link\", rel=lambda v: v and \"stylesheet\" in v.lower()):\n",
    "        link_tag.decompose()\n",
    "\n",
    "    # コメント削除\n",
    "    for comment in soup.find_all(string=lambda text: isinstance(text, Comment)):\n",
    "        comment.extract()\n",
    "\n",
    "    # <input> やフォーム系タグを削除（\"input\" 文字が出ないように）\n",
    "    for tag in soup.find_all([\"input\", \"form\", \"select\", \"option\", \"textarea\", \"button\"]):\n",
    "        tag.decompose()\n",
    "\n",
    "    # 装飾系属性を削除\n",
    "    css_like_attrs = {\n",
    "        \"style\",\n",
    "        \"class\",\n",
    "        \"id\",\n",
    "        \"width\",\n",
    "        \"height\",\n",
    "        \"align\",\n",
    "        \"valign\",\n",
    "        \"bgcolor\",\n",
    "        \"border\",\n",
    "        \"cellpadding\",\n",
    "        \"cellspacing\",\n",
    "        \"color\",\n",
    "        \"background\",\n",
    "    }\n",
    "    for tag in soup.find_all(True):\n",
    "        for attr in list(tag.attrs):\n",
    "            if attr.lower() in css_like_attrs:\n",
    "                del tag.attrs[attr]\n",
    "\n",
    "\n",
    "def extract_tables_and_replace_with_tokens(\n",
    "    soup: BeautifulSoup,\n",
    ") -> Tuple[str, List[Tuple[str, str]]]:\n",
    "    tables: List[Tag] = soup.find_all(\"table\")\n",
    "    token_table_pairs: List[Tuple[str, str]] = []\n",
    "\n",
    "    for idx, table in enumerate(tables, start=1):\n",
    "        token = TABLE_TOKEN_TEMPLATE.format(idx=idx)\n",
    "        table_html = str(table)\n",
    "        token_table_pairs.append((token, table_html))\n",
    "        table.replace_with(NavigableString(token))\n",
    "\n",
    "    return str(soup), token_table_pairs\n",
    "\n",
    "\n",
    "def html_to_markdown(html: str) -> str:\n",
    "    return md(\n",
    "        html,\n",
    "        heading_style=\"ATX\",\n",
    "        bullets=\"-\",\n",
    "        escape_asterisks=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def restore_tables_into_markdown(\n",
    "    markdown_text: str, token_table_pairs: List[Tuple[str, str]]\n",
    ") -> str:\n",
    "    for token, table_html in token_table_pairs:\n",
    "        markdown_text = markdown_text.replace(token, f\"\\n{table_html}\\n\")\n",
    "    return markdown_text\n",
    "\n",
    "\n",
    "def fix_numbered_headings(markdown_text: str) -> str:\n",
    "    \"\"\"\n",
    "    先頭が「1. **タイトル**」「1.1 **タイトル**」のような行を\n",
    "    # / ## / ### ... の見出しに変換します。\n",
    "    \"\"\"\n",
    "    lines = markdown_text.splitlines()\n",
    "    new_lines: List[str] = []\n",
    "\n",
    "    # 例:\n",
    "    # \"1. **各国の経済状況**\" → \"# 各国の経済状況\"\n",
    "    # \"1.1 **主要国での比較**\" → \"## 主要国での比較\"\n",
    "    # 太字(** **)が無いケースも一応許容します\n",
    "    pat = re.compile(r\"^\\s*(\\d+(?:\\.\\d+)*)\\s+(?:\\*\\*(.+?)\\*\\*|(.+))\\s*$\")\n",
    "\n",
    "    for line in lines:\n",
    "        m = pat.match(line)\n",
    "        if m:\n",
    "            numbering = m.group(1)\n",
    "            title = m.group(2) or m.group(3) or \"\"\n",
    "            level = min(len(numbering.split(\".\")), 6)\n",
    "            new_lines.append(f\"{'#' * level} {title.strip()}\")\n",
    "        else:\n",
    "            new_lines.append(line)\n",
    "\n",
    "    # 先頭に \"input\" 単独行が残っている場合の対策（安全側）\n",
    "    if new_lines and new_lines[0].strip().lower() == \"input\":\n",
    "        new_lines = new_lines[1:]\n",
    "\n",
    "    return \"\\n\".join(new_lines)\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    if not INPUT_HTML.exists():\n",
    "        raise FileNotFoundError(f\"入力HTMLが見つかりません: {INPUT_HTML}\")\n",
    "\n",
    "    soup = load_html(INPUT_HTML)\n",
    "\n",
    "    # CSSや関連属性を除去 + input等を除去\n",
    "    remove_css_and_related_attrs(soup)\n",
    "\n",
    "    # テーブル抽出 & トークン置換\n",
    "    html_without_tables, token_table_pairs = extract_tables_and_replace_with_tokens(soup)\n",
    "\n",
    "    # Markdownへ変換\n",
    "    markdown_text = html_to_markdown(html_without_tables)\n",
    "\n",
    "    # テーブルHTMLをMarkdownへ差し戻し\n",
    "    markdown_text = restore_tables_into_markdown(markdown_text, token_table_pairs)\n",
    "\n",
    "    # 番号付き見出しを # 見出しへ補正\n",
    "    markdown_text = fix_numbered_headings(markdown_text)\n",
    "\n",
    "    # 出力\n",
    "    OUTPUT_MD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    with OUTPUT_MD.open(\"w\", encoding=\"utf-8\", newline=\"\\n\") as f:\n",
    "        f.write(markdown_text)\n",
    "\n",
    "    print(f\"変換が完了しました: {OUTPUT_MD}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt_book",
   "language": "python",
   "name": "prompt_book"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
